题目,思路,属性,类型
最大值与最小值的变量关系表示,"1、最大值变量表示：$U=\max (X, Y)=\frac{X+Y+|X-Y|}{2}$

2、最小值变量表示：$V=\min (X, Y)=\frac{X+Y-|X-Y|}{2}$",基础,概率论通识
事件,"事件与样本空间：
1、随机试验：1、同条件可重复；2、实验开始前无法预知结果；3、结果可能有多个
2、样本空间：1、随机试验的每一个结果为样本点；所有的样本点组成样本空间
3、随机事件：1、样本空间的子集称为随机事件，简称事件；2、一个样本点组成的事件为基本事件；3、必然事件和不可能事件的定义
——————————————————————————
事件的基本运算：
1、事件的并、交、差、包含、相等
2、运算规律：交换律、结合律、分配律、对偶律
3、运算过程中对一个等式两边与同一事件相交，等式仍成立；反之不能成立（没有消去律：等式两边同时消去同一个交事件等式不能成立）
备注：可以使用图形（文氏图）求解或对结果进行验证
——————————————————————————
文字叙述：（正确理解至少、最少、最多、恰有的含义）
1、至少（最少）：求反向事件（一个都没有，几个都没有）
2、最多：求反向事件（多于最多时的情况，大概率没有等号，即不包含最多）
3、恰有：直接求
注意：同一事件会有多种不同的表达形式
——————————————————————————
事件相互独立：
1、定义：相互独立是指事件集合的任意的子集都互相独立
2、独立事件的充要条件：$P(AB)=P(A)P(B)$（备注：常用用判断两个事件是否是相互独立的）
3、两事件$A,B$相互独立的充要条件是$A$与$\overline B$，或$\overline A$与$B$，或$\overline A$与$\overline B$相互独立（事件独立得到的推论，$A,B$独立并不意味着$A$与$\overline B$就不是独立的，这是个双重否定，害，真拗口，总而言之就是$A,B$相互独立则所有相关的都互相独立）
4、当$0<P(A)<1$时，$A \  B$独立等价于$P(B|A)=P(B)$（一个事件在另一个事件条件下的概率与事件单独发生的概率一致，则这两个事件独立）或者$P(B|A)=P(B|\overline A)$成立（证明：使用条件概率公式）
5、相互独立的n个事件中，任何几个事件换成对立事件，新组成的n个事件也相互独立（利用了上述3的推论）
备注：独立是指两个事件互不影响",基础,随机事件和概率
事件独立、不相容（也叫互斥）、对立的对比,"1、事件独立：依据事件独立公式$P(AB)=P(A)P(B)$，$A,B$事件的发生互不影响（独立性要求两个变量完全不相关；不相关要求两个变量没有线性关系）
2、事件对立：两个事件$A,B$占满了同一个样本空间（对立事件组成并占满整个样本空间），并且彼此之间没有交集
3、事件不相容（互斥）：两个事件没有交集（事件不能同时发生，没有公共样本点），但是不一定占满了整个样本空间
注意：互斥事件与对立事件的区别是互斥可能没有占据整个样本空间",基础,随机事件和概率
概率,"概率的概念和基本运算：
1、概率定义：对应样本空间的实值函数P（即使事件存在也可以使事件概率为0，使用图形法计算事件的关系时，注意区分事件和概率）
2、任意事件概率：$0 \leqslant P(A)\leqslant 1$
3、必然事件概率为1（$P(\Omega)=1$）；空集的概率为0（$P(\emptyset)=0$）
4、两两互斥（不相容）的事件并等于对应每一个事件概率的和（$P\left(A_{1} \cup A_{2} \cup \cdots \cup A_{n}\right)=\sum_{i=1}^{n} P\left(A_{i}\right)$）
5、$P(A)=1-P(\overline A)$ 常用
6、$A \subset B\rightarrow P(A) \leqslant P(B)$：事件的包含与概率的大小的关系比较（事件关系与概率关系对应）
——————————————————————————
区分概率与事件：
1、概率的定义为对应样本空间的实值函数（每一个样本都有一个概率值，即使样本存在概率可能也是零）
2、区分概率和事件的运算的区别，事件相等概率是相等的，但是概率相等事件不一定等同
文氏图法：通过图的相交或者分离表示事件事件的关系，对每一个区域标注变量表示事件区域的概率
——————————————————————————","基础, 思路",随机事件和概率
概率计算公式,"加法公式：
1、$P(A\cup B) = P(A)+P(B)-P(AB)$
2、$P(A\cup B \cup C) = P(A)+P(B)+P(C)-P(AB)-P(AC)-P(BC)+P(ABC)$
——————————————————————————
减法公式：
1、$P(A - B) = P(A)-P(AB)$
2、$A-B=A\overline B \rightarrow P(A-B) = P(A\overline B)$ （注意：如果AB互相独立，则$P(A-B) = P(A\overline B)=P(A)P(\overline B)$，利用了相互独立的公式）
——————————————————————————
乘法公式：
1、$P(A)>0 \rightarrow P(AB)=P(A)P(B|A)$（非独立时乘法运算）
2、$P(A_1A_2\cdots A_n) > 0 \rightarrow P(A_1A_2\cdots A_n)=P(A_1)P(A_2|A_1)\cdots P(A_n|A_1A_2\cdots A_{n-1})$
3、推论：$P(AB) \le P(A)$
备注：事件的相乘是以前提条件为基础的，所以转化成了条件概率
——————————————————————————
全概率公式：
1、条件：$\mathop{ \bigcup }\limits_{{k=1}}^{{n}}\mathop{{B}}\nolimits_{{k}}=\Omega \ $，$\mathop{{B}}\nolimits_{{i}}\mathop{{B}}\nolimits_{{j}}= \emptyset { \left( {i \neq j,i,j=1,2,3, \cdots n} \right) }$，$P{ \left( {\mathop{{B}}\nolimits_{{k}}} \right) } > 0{ \left( {k=1,2,3, \cdots n} \right) }$；（称$B_1,B_2,\cdots B_n$为$\Omega$的一个完备事件组）
2、结论：$P{ \left( {A} \right) }=\mathop{ \sum }\limits_{{k=1}}^{{n}}P{ \left( {\mathop{{B}}\nolimits_{{k}}} \right) } \cdot P{ \left( {A \left| \mathop{{B}}\nolimits_{{k}}\right. } \right) }$
备注：事件$B_i$瓜分了整个样本空间，相当于A样本空间的基底？
——————————————————————————
贝叶斯公式：
1、条件：$\mathop{ \bigcup }\limits_{{k=1}}^{{n}}\mathop{{B}}\nolimits_{{k}}=\Omega$，$\mathop{{B}}\nolimits_{{i}}\mathop{{B}}\nolimits_{{j}}= \emptyset { \left( {i \neq j,i,j=1,2,3, \cdots n} \right) }$，$P(A) > 0,P{ \left( {\mathop{{B}}\nolimits_{{k}}} \right) } > 0{ \left( {k=1,2,3, \cdots n} \right) }$
2、结论：$P{ \left( {\mathop{{B}}\nolimits_{{k}} \left| A\right. } \right) }=\frac{{P \left( {\mathop{{B}}\nolimits_{{k}}} \left) \cdot P{ \left( {A \left| {\mathop{{B}}\nolimits_{{k}}}\right. } \right) }\right. \right. }}{{\mathop{ \sum }\limits_{{i=1}}^{{n}}P{ \left( {\mathop{{B}}\nolimits_{{i}}} \right) } \cdot P{ \left( {A \left| \mathop{{B}}\nolimits_{{i}}\right. } \right) }}}=\frac{{P \left( {\mathop{{B}}\nolimits_{{k}}} \left) \cdot P{ \left( {A \left| {\mathop{{B}}\nolimits_{{k}}}\right. } \right) }\right. \right. }}{P(A)}$，换算得到$P(B|A)=P(B)\cdot \frac{P(A|B)}{P(A)}$
3、作用：新信息出现后的B概率=B概率 X 新信息带来的调整（理解调整式子$\frac{P(A|B)}{P(A)}$的计算，依据代数来理解，无法理解，记住公式）
问题：贝叶斯公式能用来干什么？
——————————————————————————
其它公式（AB独立时）：
1、$P(A-B) = P(A\overline B)=P(A)P(\overline B)$（事件的减法公式与独立时的进一步推广）
2、$P(A\cup B) = 1-P(\overline A \  \overline B) = 1-P(\overline A)P(  \overline B)$（利用事件的图形关系可以解释）
——————————————————————————
备注：可以利用事件的图形关系进行辅助理解上述公式","基础, 疑问",随机事件和概率
常见的事件模型,"古典模型：
1、实验结果为n个样本点，每个样本点的发生有相同的可能性，事件A由$n_A$个样本点组成，则事件A的概率为$P(A) = \frac{n_A}{n} = \frac{A包含的样本点数}{样本点总数}$
注意：特点为有限等可能试样
注意：计算时，尽可能选择较小并且简单的样本空间
如何判断和发现最简单的样本空间，或者发现样本空间？整理一下技巧
——————————————————————————
几何型概率：
1、试验的样本空间为区域，以$L(\Omega)$表示其几何度量，$L(\Omega)$有限，且试验结果出现在$\Omega$中的任何区域只与该区域的几何度量成正比，事件A的样本点所表示的区域为$\Omega _A$，则事件A的概率为$P(A) = \frac{L(\Omega _A)}{L(\Omega)} = \frac{\Omega _A的几何度量}{\Omega 的几何度量}$
注意：样本点无限，几何度量上是等可能的
——————————————————————————
独立重复实验与$n$重伯努利实验：
1、独立重复试验：一随机实验做若干次，各次试验所联系的事件相互独立，且同一事件在各个事件在各个试验中出现的概率相同
2、伯努利试验：独立重复试验中只有两个结果
3、n重伯努利实验：伯努利试验重复$n$次
4、n重伯努利试验中事件A（$P(A) = p \ (0<p<1)$）发生$k$次的概率$C_n^kp^k(1-p^{n-k}),k=0,1,2,\cdots ,n$；即二项式的展开式中的项
思路：独立重复实验中如果有多个结果，可以将结果进行归成两类，转换成伯努利实验
——————————————————————————","基础, 思路, 疑问",随机事件和概率
随机变量与分布函数,"随机变量与分布函数定义：
1、随机变量：样本空间$\Omega$上的实值函数$X=X(\omega), \omega \in \Omega$，则称$X(\omega)$为随机变量，简记为$X$（和概率定义一样也是将样本空间映射成一个函数形式，将事件转换成了值（这个值是坐标轴中的横坐标），相当于是为每个$\omega \in \Omega$指定了一个实数$X(\omega)$，实值函数是根据具体的事件进行定义的，连续随机变量和离散随机变量的区别就是具体的事件可以定义成连续值还是可以定义为离散的值，比如抛几次硬币正面的次数（离散）；飞镖到圆心的距离（连续））
2、分布函数：对任意实数x，分布函数定义为$F(x) = P\{ X \le x\}, -\infty < x < +\infty$（随机变量$X$是一个值，分布函数为随机变量$X$小于某一个自变量$x$值时的概率值）
注意：分布函数是含有等号的
——————————————————————————
分布函数性质：（判定分布函数）
1、负无穷为0，正无穷为1
2、单调非减，右连续（$F(x)=F(x^+)$），左不连续（$ F(x^-) \ne F(x) , F(x^-) \le F(x) $）（左不连续才导致某一个点处概率不为0，这是由点处的概率定义得到的）
3、$P\{ x_1 < x \le x_2\} = F(x_2)-F(x_1)$
4、$P\{X=x\} = F(x)-F(x^-)$，$F(x)$在$x$点连续时，$P\{X=x\} = 0$；即只有左不连续时，说明该点存在概率，否则概率为零
——————————————————————————
离散型：
1、离散型随机变量：随机变量取值为有限多个或者可数无穷个
2、概率分布：变量可能取值为$x_1,x_2,\cdots,x_n,\cdots$，$X$取各个可能值得概率为$P\{ X = x_k \} = p_k, k=1,2,\cdots$，可用用列表给出（一维列表、二维列表）
3、性质：每个取值得概率大于等于0，总概率和为1（用来验证求解的结果）
——————————————————————————
连续型：
1、对随机变量$X$得分布函数$F(x)$存在一个非负的可积函数$f(x)$使得$F(x)=\int_{-\infty}^xf(t)dt,-\infty <x<+\infty$，称$X$为连续型随机变量，$f(x)$为$X$的概率密度
2、性质（概率密度的充要条件）：概率密度大于等于0；概率密度全域积分为1（用来验证求解的结果）
3、$P(x_1 < X \le x_2) = \int_{x_1}^{x_2}f(t)dt$（求解指定范围的概率）
4、在$f(x)$的连续点处有$F^{'}(x)=f(x)$（可以由分布函数求解概率密度）
5、$P(x_1 < X < x_2) = P(x_1 < X \le x_2) = P(x_1 \le X < x_2) = P(x_1 \le X \le x_2)$（连续性随机变量范围区间是否闭合不影响变量范围的概率，因为对于连续型每一个具体点的概率都是0）
6、概率密度函数上某一个点的值是概率在该点的变化率，而不是概率的值
注意：连续型随机变量的分布函数一定可以表示成$F(x)=\int_{-\infty}^xf(t)dt$，所以这时的$F(x)$一定是全域上的连续函数，也就是不连续的$F(x)$一定不是连续随机变量；反之，不能说连续的$F(x)$对应的$X$一定是连续型随机变量，只有有概率密度的随机变量才称作连续性随机变量（例如：这里需要补充反例）
注意：连续型随机变量的$F(x)$一定连续，但是$f(x)$不一定是连续的（例如：分布函数含有尖锐的点）
——————————————————————————",基础,随机变量及其概率分布
常用的分布,"常见的分布：
1、0-1分布：1重伯努利试验
2、二项分布：n重伯努利试验，$n$次独立重复试验中成功的次数；$X \sim B(n,p)$
3、几何分布：独立重复试验，每次试验成功率为$p$，则在k次试验时首次试验才成功的概率，$P\{X=k\}=p q^{k-1}, k=1,2, \cdots$
4、超几何分布：N件产品含有M件次品，从中取$n$件（不放回抽取），令事件$X$为抽取的$n$件产品含有的次品个数，则$X$服从参数为$n$，$M$，$N$的超几何分布，$P\{X=k\}=\frac{\mathrm{C}_{M}^{k} \mathrm{C}_{N-M}^{n-k}}{\mathrm{C}_{N}^{n}}, k=l_{1}, \cdots, l_{2}$
5、泊松分布：$P(x) = \frac{\lambda^k}{k!}e^{-\lambda},X \sim P(\lambda)$ ：（k的范围是0,1,2...）一段时间内电话总机接到的次数，候车的旅客数，保险索赔次数
6、均匀分布：$X \sim U(a,b)$
7、指数分布：$f(x) = \begin{cases} \lambda e^{-\lambda x}, & x > 0, \\[5ex] 0, & x \le 0, \end{cases} \ \ \lambda >0$；$X \sim E(\lambda)$
8、正态分布：$f(x)=\frac{1}{\sqrt{{2\pi}}\times\sigma}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$；$X \sim N(\mu,\sigma^2)$

备注：所有的表达式与表示方法要记牢
——————————————————————————
二项分布和泊松分布和之间的联系：（泊松定理，按照大概了解即可）
1、$\lim_{n \rightarrow \infty}np_n=\lambda, n\ge1000,p\le0.1 \rightarrow \lim _{n \rightarrow \infty} C_{n}^{k} p_{n}^{k}\left(1-p_{n}\right)^{n-k}=\frac{\lambda^{k}}{k !} \mathrm{e}^{-\lambda}$，即二项分布转换成泊松分布的条件和形式（对于$\lim_{n \rightarrow \infty}np_n=\lambda$中$p_n$是一个事件A在实验中出现的概率，它与实验的总数$n$有关）
2、应用条件：n比较大，$\lambda$比较小（$n\ge1000,p\le0.1$）
注意：分布之间关联参数的关系
——————————————————————————","基础, 疑问",随机变量及其概率分布
常见的分布的性质,"指数分布的无记忆性：
1、$P\{X>t\}=\int_{t}^{+\infty} \lambda \mathrm{e}^{-\lambda t} \mathrm{~d} t=\mathrm{e}^{-\lambda t}, t>0$
2、$P\{X>t+s \mid X>s\}=\frac{P\{X>t+s\}}{P\{X>s\}}=\frac{\mathrm{e}^{-\lambda(t+s)}}{\mathrm{e}^{-\lambda s}}=\mathrm{e}^{-\lambda t}=P\{X>t\}, t, s>0$（利用定义式推导）
备注：求解指数分布的条件概率时可能用的到
——————————————————————————
正态分布性质：
1、标准化形式：$F(x)=\Phi\left(\frac{x-\mu}{\sigma}\right)$
2、范围求解：$P\{a<X \leqslant b\}=\Phi\left(\frac{b-\mu}{\sigma}\right)-\Phi\left(\frac{a-\mu}{\sigma}\right), a<b$
3、性质：概率密度 $f(x)$ 关于 $x=\mu$ 对称, $\varphi(x)$ 是偶函数（根据图像可以推导）
4、性质：$\Phi(-x)=1-\Phi(x), \Phi(0)=\frac{1}{2}$（根据图像可以推导）
5、性质：当 $X \sim N(0,1)$, 有 $P\{|X| \leqslant a\}=2 \Phi(a)-1$（根据图像可以推导）
6、性质：若$X_{1} \sim N\left(\mu_{1}, \sigma_{1}^{2}\right), X_{2} \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$，$X_{1}$与$X_{2}$相互独立，则$a X_{1}+b X_{2} \sim N\left(a \mu_{1}+b \mu_{2}, a^{2} \sigma_{1}^{2}+b^{2} \sigma_{2}^{2}\right)$（正态分布的组合性质）",基础,随机变量及其概率分布
离散型随机变量的函数分布,"（离散）函数分布的定义：
1、设X的分布律为$P\{X=x_k\}=p_k,k=1,2,\cdots$，则X的函数$Y=g(X)$的分布律为$P\{Y=g(x_k)\}=p_k,k=1,2,\cdots$，如果在$g(x_k)$中有相同的数值，则将它们相应的概率和作为$Y$取该值的概率（合并相同的值）
——————————————————————————
（离散）函数分布的求解：
1、将X的值代入到转换函数中，得到新的值Y，并于原X的概率值进行对应
2、将相同的Y值得概率合并
3、得到新的Y和对应得概率值","中等, 基础",随机变量及其概率分布
连续型随机变量的函数分布,"（连续）函数分布的定义：
1、公式法：设$X$是一个具有概率密度$f_X(x)$的随机变量，又设$y=g(x)$是单调，导数不为零的可导函数，$h(y)$为它的反函数，则$Y=g(X)$的概率密度为$f_{Y}(y)=\left\{\begin{array}{cc}\left|h^{\prime}(y)\right| f_{X}(h(y)), & \alpha<y<\beta, \\0, & \text { 其他, }\end{array}\right.$其中，$(\alpha,\beta)$是函数$g(x)$在$x$可能取值的区间上的值域（用公式法时，因要求条件较多：单调，可导，导数不为零，反函数存在等，实际求解比较麻烦；）（推导：$F_{X}(x)=P\{X \leqslant x\}=\int_{-\infty}^{x} f_{X}(t) \mathrm{d} t, x=h(y) \Rightarrow F_{Y}(y)=P\{Y \leqslant h(y)\}=\int_{-\infty}^{h(y)} f_{X}(t) \mathrm{d} t$，然后求导得到概率密度（加绝对值，因为$h(y)$只有单调递增和单调递减两种情况，加绝对值为了防范单调递减的情况））
2、定义法：先求Y的分布函数$F_{Y}(y)=P\{Y \leqslant y\}=P\{g(X) \leqslant y\}=\int_{g(x) \leqslant y} f_{X}(x) \mathrm{d} x, $然后利用$f_{Y}(y)=F_{Y}^{\prime}(y)$ 求解概率密度（用定义法时，实际上就是求积分$\int_{g(x) \leqslant y} f_{X}(x) \mathrm{d} x$，只要掌握好y变化的范围，不同范围和不同积分限的求积就不难求得$F_Y(y)$）
备注：公式法在于对上限进行转换；定义法在于对随机变量转换
——————————————————————————
（连续）函数分布的求解（公式法）：
1、将反函数$h(y)$代入到公式即可，$f_{Y}(y)=\left\{\begin{array}{cc}\left|h^{\prime}(y)\right| f_{X}(h(y)), & \alpha<y<\beta, \\0, & \text { 其他, }\end{array}\right.$
注意：对于转换函数，需要单调，导数不为0，存在反函数（即转换函数是严格单调递增或者递减函数，这是为了保证$x$与$y$一一对应）
——————————————————————————
（连续）函数分布的求解：（定义法）（连续转连续）
1、根据$X$变量的范围判断$Y$的值域（如果转换函数$y=g(x)$比较复杂，绘制$X$与$Y$的函数图像，进行判断，下面简称图像）
2、求解$Y$变量的分布函数（$F(y)=P\{ Y \leqslant y \}$，$y$即为$y=g(x)$图像上的水平线，代表$y=y_1$直线）
3、根据$Y\leqslant y$判断$g(x) \leqslant y$对应的$X$的范围（该范围是用$y$来表示的，至少有一端必须是这样）
4、求解$X$的概率密度在该范围上的积分，得到关于$y$的函数，即为$Y$变量的分布函数
5、对$Y$的分布函数进行求导即可得到$Y$变量的概率密度
注意：当题目需要求解$Y$变量的概率密度时，可以省略第四步的积分过程，利用变上下限积分的求导公式求导（注意下限有一个负号）
——————————————————————————
（连续）函数分布的求解：（定义法）（连续转离散，或者是依据对应关系）<复习全书 P493 例4>
1、已知$X$（已知类型或者分布的随机变量）和$Y$（未知类型或者分布的随机变量）的对应关系式
2、设待求的$Y$变量在关系式中是离散的几个点，或者连续加离散
3、求解$Y$的范围（$P\{Y \leqslant  \}$或者$P\{Y = \}$（离散））对应的$X$的范围（$P\{X\leqslant \}$的概率","中等, 基础",随机变量及其概率分布
分布函数或者概率密度（分布律）的求解,"具体事件的概率分布和分布函数：
1、判断事件所属的分布类型
2、套用分布类型求解
3、如果是正态分布求解一般会将正太分布标准化
——————————————————————————
分布律（概率分布）的未知参数：
1、连续概率密度性质：在全域上大于0 AND 全域上积分为1（概率密度的充要条件）（可以用来判断复合函数是否是概率密度）
2、离散分布律性质：在全域上大于0 AND 全域上概率和为1（分布律的充要条件）
3、分布函数性质：单调递增，负无穷为0，正无穷为1，右连续（$F(x)=F(x^+)$，一般适用于分段函数间断位置求解，看清分段函数等号的位置，是否可以用右连续的条件）
——————————————————————————
分布律求分布函数：（离散）
1、离散情况表示成分段函数的形式（不要忘记两边的两项）
注意：正无穷远为1（即分段函数有一项条件大于指定值的值为1）；类似必有一项负无穷远为0；不要忘记这两项
——————————————————————————
概率密度求分布函数：（连续）
1、对概率密度求变上限的积分",中等,随机变量及其概率分布
二维随机变量相关性质,"分布函数性质：（连续）
1、单调不减、右连续、有界（分布函数均有的性质，无论什么类型）
2、$F(X,Y)$为二元连续函数（可导性怎么说？）
3、如果$F(X,Y)$是连续且可导的，则二位随机变量是连续的（连续随机变量的充分条件）
——————————————————————————
概率密度性质：（连续）
1、非负性（是概率密度函数充分条件之一）
2、在$R^2$上积分为1（是概率密度函数充分条件之二）
3、改变概率密度个别线上的值，$f(x,y)$仍是概率密度（个别线上的值不影响积分的值）
4、连续随机变量的概率密度是分布函数对$xy$的偏导数$dxdy$（二维上根据分布函数求解概率密度）
5、平面区域的概率等于概率密度在该区域上的积分（二维上求解某个区域的概率）
——————————————————————————
求解概率密度中的未知参数：（连续）
1、利用连续概率密度的性质：二重积分为1；非负
2、利用分布函数的性质：分布函数为连续可导的函数（即分布函数是平滑的）
——————————————————————————
分布函数性质：（离散）
1、单调不减、右连续、有界（分布函数均有的性质，无论什么类型）
——————————————————————————
概率分布性质：（离散）
1、二维随机变量的联合概率分布表示两个随机事件同时发生的概率
2、联合概率分布具有非负性
3、联合概率分布的和为1（验证计算结果的正确性）
——————————————————————————
求解分布律中的未知参数：（离散）
1、边缘分布与相应行/列的加减关系
2、分布律中的数值 = 对应行的概率密度 X 对应列的边缘分布（只有在二维变量独立的情况下成立）
3、分布律中对应行的概率成比例（只有在二维变量独立的情况下成立）","基础, 疑问",多维随机变量及其分布
二维边缘概率密度与边缘分布函数定义与求解,"定义：
1、边缘概率密度公式定义为：关于$X$的边缘概率密度为将$Y$方向向$X$轴收缩（二维概率密度对y进行积分，$f_{X}(x)=\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} y$）；关于$Y$的边缘概率密度类似
2、边缘分布函数定义为：关于$X$的边缘分布函数为关于$X$的边缘概率密度在$(-\infty,x)$上的积分（$F_{X}(x)=F(x,+\infty)=\int_{-\infty}^{x}\left[\int_{-\infty}^{+\infty} f(x, y) \mathrm{d} y\right] \mathrm{d} x$）；关于$Y$的边缘分布函数类似
——————————————————————————
离散随机变量-求解：
1、求解$X$的边缘概率密度分布相当于将某个$X$值对应的所有的$Y$值得概率相加，得到该$X$值得边缘概率密度分布；求解$Y$的边缘概率密度分布类似
——————————————————————————
连续随机变量-求解：
1、求解$X$的边缘概率密度时对$Y$进行积分（积分域如果与$x$有关则用$x$表示，否则就是$Y$变量的有效范围）；求解$Y$的类似
2、如果已知$X,Y$相互独立，则二维随机变量的概率密度可以分解成$X$和$Y$的边缘概率密度相乘的形式（验证边缘概率密度求解的正确性）
——————————————————————————
二维随机变量分布函数求解边缘分布函数：（连续）
1、求解$X$的分布函数时将分布函数中$Y$随机变量设置为无穷大值；求解$Y$的类似
2、公式：$F_X(x)=P\{X \le x\} = P\{X \le x,Y<+\infty\} = F(x, +\infty)$；$F_Y(y)$类似
——————————————————————————
二维随机事件的分布率和边缘分布：（离散）（具体事件）
1、列出所有的可能性和计算对应的概率（$P\{X=val_1,Y=val_2\} = p$）
2、列出分布律和边缘分布（第一个变量为竖行，边缘概率密度中代表$i,p_{i\cdot}$，第二个变量对应为横行，边缘概率密度中代表$j,p_{\cdot j}$）
3、验证概率和为1（验证求解的正确性）","基础, 简单",多维随机变量及其分布
求解分布函数（分布律）或概率密度,"由两个变量的概率密度时求解二维分布函数：（连续、离散）
1、定义：$F(x,y)=P\{ X \le x, Y \le y \}$，在概率密度函数中，$x$和$y$有关联时，利用绘图确定分布函数的积分范围（将积分变量和积分上下限变量区分开）
——————————————————————————
由两个独立变量的概率密度时求解联合概率密度（分布律）：（连续、离散）
1、联合概率密度：$X,Y$的（边缘）概率密度（分布律）的乘积
注意：独立是前提条件",中等,多维随机变量及其分布
求解条件概率,"由二维随机概率密度求解条件概率：（连续）
1、利用条件概率密度的公式$P\{X>x|Y>y\} = \frac {P\{X>x,Y>y\}}{P\{Y>y\}}$，利用边缘概率密度和二维概率密度求解
2、画出图形（二维坐标系）辅助理解
——————————————————————————
由二维随机概率密度求解条件概率：（二维均匀分布）
1、求解二维随机变量的概率密度
2、根据二维变量的概率密度求解边缘概率密度
3、条件概率密度=二维变量的概率密度/对应的边缘概率密度
4、如果是具体值的条件，则可以根据图形进行求解（又快又稳）
注意：标注条件概率密度中的范围（条件概率密度的范围是由对应的边缘概率密度的范围决定的）
——————————————————————————
由二维随机分布律求解条件分布律：（离散）
1、利用条件概率密度的公式，利用二维随机变量概率密度和边缘概率密度求解
2、公式：$P\{X=x|Y=y\} = \frac {P\{X=x,Y=y\}}{P\{Y=y\}} = \frac {p_{ij}}{p_{\cdot j}}$
——————————————————————————",中等,多维随机变量及其分布
条件分布律（概率密度）、分布律（概率密度）、边缘分布律（概率密度）：知二求一（离散、连续）,"1、求解条件分布律（概率密度）：二维随机变量的分布律（概率密度）除以相应的边缘分布律（概率密度），就是对应的条件分布律（概率密度）
2、求解二位随机变量的分布律（概率密度）：条件分布律（概率密度）乘以对应的边缘分布律（概率密度）（对连续情况特别注意：如果条件概率密度的条件是存在范围的（即条件对应的边缘概率密度的存在范围，条件概率密度离开对应的边缘概率密度的存在也不能存在），一定要验证该范围下求得的分布律是否就已经是全域的分布律了，即对该范围内积分与全域积分对比并且都是1，表明其它范围都是0，从而将求得的局限的分布律（即局限在条件概率密度的条件（对应的边缘概率密度）存在范围）推广到全域上）
3、求解边缘分布律（概率密度）：二位随机变量的分布律（概率密度）除以条件分布律（概率密度）
备注：离散的条件密度（$P\{X=x|Y=y\} = \frac {P\{X=x,Y=y\}}{P\{Y=y\}}$）
备注：条件分布定义（$F_{X \mid Y}(x \mid y)=\int_{-\infty}^{x} \frac{f(s, y)}{f_{Y}(y)} \mathrm{d} s$）和条件密度定义（$f_{X \mid Y}(x \mid y)=\frac{f(x, y)}{f_{Y}(y)}, f_{Y}(y)>0$）
注意：具有范围的相乘时，标注清楚变量的范围（函数定义域），求解完后记得验证",中等,多维随机变量及其分布
根据分布律（概率密度）和边缘概率密度运用,"变量独立性判断：（离散）
1、分布律中的数值 等于 对应行的边缘分布值 X 对应列的边缘分布值（即二位分布律等于边缘分布律的乘积） ，则是独立的
——————————————————————————
变量独立性判断：（连续）
1、根据概率分布等于边缘概率密度的乘积，则是独立的","思路, 简单",多维随机变量及其分布
二维随机变量的概率,"连续二维变量的概率：（均匀分布）
1、求解整体的区域积分，根据积分为1求解未知参数（如果有未知参数的话）
2、求解指定区域的积分，得到指定区域的概率
3、也可以用积分的比值来求解（面积的比值，因为均匀分布是均匀的），不需要求出具体的概率
——————————————————————————
连续二维变量的组合的概率：（组合形式）
1、连续二维随机变量概率密度是平面上具有值（然后就成了三维，第三个维度是分布函数在该点的变化率，积分就是概率值）
2、二维随机变量的函数组合就是在二维随机变量的概率密度上求解满足该组合（满足组合起来的指定条件）的区域，然后在该区域上积分
——————————————————————————
连续二维变量的函数组合的概率：（正态分布）（组合形式）
1、方案一：将变量设为极坐标形式转换为角度形式，求解积分（$(X, Y) \sim N\left(\mu_{1}, \mu_{2} ; \sigma_{1}^{2}, \sigma_{2}^{2} ; 0\right)$对应$P\{X<Y\}=\iint_{x<y} \frac{1}{2 \pi \sigma^{2}} \mathrm{e}^{-\frac{1}{2 \sigma^{2}}\left[(x-\mu)^{2}+(y-\mu)^{2}\right]} \mathrm{d} x \mathrm{~d} y$，使用极坐标$\{\begin{array}{l}x-\mu=r \cos \theta, \\ y-\mu=r \sin \theta,\end{array}$代换得到$P\{X<Y\}=\frac{1}{2 \pi \sigma^{2}} \int_{\frac{\pi}{4}}^{\frac{5}{4} \pi} \mathrm{d} \theta \int_{0}^{+\infty} \mathrm{e}^{-\frac{r^{2}}{2 \sigma^{2}}} r \mathrm{~d} r=\frac{1}{2}$）
2、方案二：将变量转换到一边作为变量组合，求解该变量组合对应的分布（一般需要正态分布的两个随机变量独立，求解变量组合后的$\mu$和$\sigma^{2}$，合并成一个新的分布）根据该新的分布来求解
注意：方法二求解新的分布计算量小
——————————————————————————",中等,多维随机变量及其分布
常用二维分布,"二维均匀分布：
1、公式：$f(x, y)=\left\{\begin{array}{lc} \frac{1}{A}, & (x, y) \in G, \\ 0, & \text { 其他 }, \end{array}\right.$其中A是平面有界区域$G$的面积，则称$(X,Y)$服从区域$G$上的均匀分布
——————————————————————————
二维正态分布：
公式：$f(x, y)=\frac{1}{2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}} \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}-\frac{2 \rho\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}}\right]\right\}, -\infty<x<+\infty,-\infty<y<+\infty$，其中$\mu_{1}, \mu_{2}, \sigma_{1}>0, \sigma_{2}>0,-1<\rho<1$ 均为常数, 则称 $(X, Y) $服从参数为$\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}$和$\rho$的二维正态分布,记作$(X, Y) \sim N\left(\mu_{1}, \mu_{2} ; \sigma_{1}^{2}, \sigma_{2}^{2} ; \rho\right)$
性质：
1、$\left(X, Y\right) \sim N\left(\mu_{1}, \mu_{2} ; \sigma_{1}^{2}, \sigma_{2}^{2} ; \rho\right)$时, $X$与$Y$均服从一维正态：$X \sim{N}\left(\mu_{1}, \sigma_{1}^{2}\right), Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$
2、$(X, Y) \sim N\left(\mu_{1}, \mu_{2} ; \sigma_{1}^{2}, \sigma_{2}^{2} ; \rho\right)$时, $X$与$Y$相互独立的充分必要条件是$\rho=0$（正态的独立与不相关是一致的）
3、$(X, Y)$服从二维正态时,行列式$\left|\begin{array}{ll}a & b \\ c & d\end{array}\right| \neq 0$时$(a X+b Y, c X+d Y)$也服从二维正态（二维正态的满足特定条件（即两个新变量没有常数倍关系，如果有会发生什么）的组合还是二维正态）； $ a X+b Y$服从一维正态$\left(a^{2}+b^{2} \neq 0\right)$（这是由性质1得出的，需要相互独立条件）
4、约定: 当$X$与$Y$均服从一维正态，且相互独立，就是指$(X, Y)$服从二维正态
5、如果$X$与$Y$均服从一维正态, 不能保证$(X, Y)$服从二维正态, 也不能保证$a X+b Y$服从一维正态（两个一维正态推不出来组合是一维的，也不能保证能组合出来二维的（需要相互独立的条件））",基础,多维随机变量及其分布
"二维随机变量函数$Z=g(X, Y)$的求解","分布律求解：（离散型）
1、Z的分布律与一维离散型求解类似，列出所有满足$Z=g(X, Y)$的概率，对相同项进行合并，或一开始就求解等于$z$的部分，得到$P\{Z = z\}$的值，即$Z$的分布律
——————————————————————————
分布函数$F_Z(z)$求解：（一般类型的X，Y）
1、公式：$F_{Z}(z)=P\{Z \leqslant z\}=P\{g(X, Y) \leqslant z\}=\iint_{g(x, y) \leqslant z} f(x, y) \mathrm{d} x \mathrm{~d} y$
注意：通常需要判断$z$的范围，保证积分区域不为0
——————————————————————————
连续与离散的组合求解：（$X$为离散，$Y$为连续）
1、对离散型变量$X$的各种取值可能用全概率公式展开：$F_{Z}(z)=P\{Z \leqslant z\}=P\{g(X, Y) \leqslant z\}$ = $\sum_{i} P\left\{X=x_{i}\right\} P\left\{g(X, Y) \leqslant z \mid X=x_{i}\right\}$ = $\sum_{i} p_{xi} P\left\{g\left(x_{i}, Y\right) \leqslant z \mid X=x_{i}\right\}$","中等, 基础",多维随机变量及其分布
二维随机变量函数$Z=X+Y$的求解（连续）,"一般类型的函数：
1、公式法：$F_{Z}(z)=P\{Z \leqslant z\}=P\{X+Y \leqslant z\}=\int_{-\infty}^{+\infty} \mathrm{d} x \int_{-\infty}^{z-x} f(x, y) \mathrm{d} y\left(\text { 或 } \int_{-\infty}^{+\infty} \mathrm{d} y \int_{-\infty}^{z-y} f(x, y) \mathrm{d} x\right)$；由此（这是求导求到里面去了？是的）可得$Z=X+Y$的概率密度为$f_{Z}(z)=\int_{-\infty}^{+\infty} f(x, z-x) \mathrm{d} x$（在$xOz$坐标中绘制范围，根据原$x,y$的范围，求解卷积公式中对应的$x,z$的范围）或者$f_{Z}(z)=\int_{-\infty}^{+\infty} f(z-y, y) \mathrm{d} y$（在$yOz$坐标中绘制范围，根据原$x,y$的范围，求解卷积公式中对应的$y,z$的范围）
2、卷积公式法：当$X$和$Y$相互独立时, $f(x, y)=f_{X}(x) f_{Y}(y)$, 则$f_{Z}(z)=\int_{-\infty}^{+\infty} f_{X}(x) f_{Y}(z-x) \mathrm{d} x$或者$f_{Z}(z)=\int_{-\infty}^{+\infty} f_{X}(z-y) f_{Y}(y) \mathrm{d} y$，这两个公式称为卷积公式,记为$f_{X} * f_{Y}$
3、定义法：根据函数绘制（在$xOy$坐标中绘制范围）在概率分布中的范围，求解未知变量的分布函数（对于该类型的求解，需要找到$g(X, Y) \leqslant z$的范围，并在该范围（范围是关于$z$的函数）上积分，即可得到$F_{Z}(z)$，对$F_{Z}(z)$求导数，即可得到$F_{Z}^{'}(z)=f_{Z}(z)$；对于$X,Y$概率密度上变量$x,y$有关联时，画出概率密度的图像，根据$Z=X+Y$求解积分范围，如果是求解概率密度，可以先对变上下限积分求导，再进行积分（技巧））
注：对于$X-Y$，$min(X,Y)$，$max(X,Y)$，$X,Y$的初等函数，$X,Y$的绝对值的求解也是类似的
——————————————————————————
相互独立的均匀分布：（相互独立的均匀分布的函数组合）
1、利用卷积公式，选定区间有限的变量为卷积区间，则$f_{Z}(z)=\int_{-\infty}^{+\infty} f_{X}(x) f_{Y}(z-x) \mathrm{d} x$（X范围有限）或者$f_{Z}(z)=\int_{-\infty}^{+\infty} f_{X}(z-y) f_{Y}(y) \mathrm{d} y$（Y范围有限）
注意：需要X,Y互相独立
——————————————————————————
相互独立（不相关）的正态分布：（相互独立的正态分布的组合）
1、相互独立的正态分布具有可加性，$X \sim{N}\left(\mu_{1}, \sigma_{1}^{2}\right), Y \sim N\left(\mu_{2}, \sigma_{2}^{2}\right)$，$Z \sim N\left(a\mu_{1}+b\mu_{2}, a^2\sigma_{1}^{2}+b^2\sigma_{2}^{2}\right)$
注意：需要X,Y互相独立","中等, 基础",多维随机变量及其分布
求解最大最小值的概率,"$P\{max(X,Y)\le z\}$，$Z=max(X,Y)$，求$F_Z(z)$：
1、理解：x和y其中的最大值小于z，所以x和y都应该小于z（因为最大的都不行，所以都不行），即可得到$F_{Z}(z)=P\{Z\le z\}=P\{max(X,Y)\le z\}=P\{X \le z\}P\{Y \le z\}=F_X(z)F_Y(z)$
——————————————————————————
$P\{max(X,Y)\ge c\}$：
1、理解：x和y其中的最大值大于c，但是其中之一可能存在小于c（最大的可以不代表另一个可以），所以转换成求解其反向的范围，转换成了x和y中的最大值小于c，所以x和y都应该小于c，即可得到$P\{max(X,Y)\ge c\}=1-P\{max(X,Y)\le c\}=1-P\{X \le c\}P\{Y \le c\}$，从直观上来看$c \rightarrow +\infty$，该式子的概率为0，$c \rightarrow -\infty$，该式子的概率为1，不可以认为是c的分布函数
——————————————————————————
$P\{min(X,Y)\le z\}$，$Z=min(X,Y)$，求$F_Z(z)$：
1、理解：x和y其中的最小值小于z，但是其中之一可能存在大于z（最小的不行不代表另一个不行），所以转换成求解其反向的范围，转换成了x和y中的最小值都大于z，所以x和y都应该大于z，即可得到$F_{Z}(z)=P\{Z\le z\}=P\{min(X,Y)\le z\}=1-P\{min(X,Y)\ge z\}=1-P\{X \ge z\}P\{Y \ge z\}=1-[1-F_X(z)][1-F_Y(z)]$
——————————————————————————
$P\{min(X,Y)\ge c\}$：
1、理解：x和y其中的最小值大于z，所以x和y都应该大于z（因为最小的都行，所以都行），即可得到$P\{min(X,Y)\ge c\}=P\{X \ge z\}P\{Y \ge z\}$，从直观上来看$c \rightarrow +\infty$，该式子的概率为0，$c \rightarrow -\infty$，该式子的概率为1，不可以认为是c的分布函数
注意：需要X,Y互相独立",中等,多维随机变量及其分布
"求解与一个离散的随机变量相关的$X_1$两个连续的随机变量$X_2,X_3$的分布函数","1、将待求解的两个随机变量的分布函数用定义表示出来$F(x,y)=P\{ X_2 \le x_2, X_3 \le x_3 \}$，其中$X_3$是与$X_1$和$X_2$相关的函数，由于$X_1$是离散的，所以利用离散与连续组合的方法将$X_3$在离散变量$X_1$上进行全概率展开，求解
注意：求解过程中可能遇到类似$P\{ X_1\le x,X_1\le y \} = P\{ X_1 \le min(x,y) \}$二维变量相关的化简情况，特别留意

2 在求解指定$x$和$y$的时候时，如果两个随机变量只与其中一个有关（相关性），可以直接代入到定义进行求解$F(x,y)=P\{ X \le x, Y \le y \}$，转换成求解指定范围的概率（存疑）","中等, 疑问",多维随机变量及其分布
数学期望定义与性质,"离散型随机变量：
1、一维：$\sum_{k=1}^{\infty}x_kp_k$
2、一维函数：$E(Y)=E[g(X)]=\sum_{k=1}^{+\infty} g\left(x_{k}\right) p_{k}$（分布律还是$X$变量的分布律，相当于套了一个函数上去，但是函数值对应的概率没有变，所以还是用的原来的分布律）
3、二维函数：$E(Z)=E[g(X, Y)]=\sum_{i=1}^{+\infty} \sum_{j=1}^{+\infty} g\left(x_{i}, y_{j}\right) p_{i j}$（分布律还是$X,Y$变量的分布律，相当于套了一个函数上去，但是函数值对应的概率没有变，所以还是用的原来的分布律）
注意：所有级数绝对收敛
——————————————————————————
连续型随机变量：
1、一维：$E(X)=\int_{-\infty}^{+\infty} x f(x) \mathrm{d} x$
2、一维函数：$E(Y)=E[g(X)]=\int_{-\infty}^{+\infty} g(x) f(x) \mathrm{d} x$（分布函数还是$X$变量的分布函数，相当于套了一个函数上去，但是函数值对应的概率没有变，所以还是用的原来的概率分布）
3、二维函数：$E(Z)=E[g(X, Y)]=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y$（分布函数还是$X,Y$变量的分布函数，相当于套了一个函数上去，但是函数值对应的概率没有变，所以还是用的原来的概率分布）
注意：所有积分绝对收敛
——————————————————————————
期望的性质：
1、性质1：$E(a_1X_1+a_2X_2+\cdots+a_nX_n+b_1+b_2+\cdots+b_m)=a_1E(X_1)+a_2E(X_2)+\cdots+a_nE(X_n)+b_1+b_2+\cdots+b_m$（无论变量之间是否独立都成立！这点很重要，可以在有些变量相关的条件下简化计算）
2、性质2：若$X$、$Y$不相关，则（相关系数计算的一部分）$C o v ( X , Y ) = E ( X Y ) - E ( X ) E ( Y ) =0$，即可以得到$E ( X Y ) = E ( X ) E ( Y )$","基础, 简单",随机变量的数字特征
方差的定义与求解,"定义：
1、方差定义：$D(X)=E\left\{[X-E(X)]^{2}\right\}$
1、标准差/均方差表示：$\sigma(X)=\sqrt{D(X)}$
2、推论1：$D(X)=E\left(X^{2}\right)-[E(X)]^{2}$（定义公式展开）
3、推论2：$E\left(X^{2}\right) \geqslant[E(X)]^{2}$（因为对任何随机变量$X, D(X) \geqslant 0$）
——————————————————————————
性质：
1、性质1（可推广）：$D(a X+b)=a^{2} D(X) $
2、性质2（前提条件：$X,Y$相互独立/不相关）：$D(X \pm Y)=D(X)+D(Y)$
3、性质2（前提条件：$X,Y$关系未知）：$D ( X \pm Y ) = D ( X ) + D ( Y ) \pm 2 Cov ( X , Y )  $（方差展开公式）（其中协方差可以用相关系数与协方差的关系替换）
——————————————————————————
根据已知概率密度求解方差：
1、先想到方差公式：$D(X)=E\left(X^{2}\right)-[E(X)]^{2}$，因为该公式只需要求一阶和二阶原点矩，已知概率密度利用原点矩的定义，很好求
2、如果方差变量是已知变量的函数形式，利用方差的性质公式进行展开","基础, 简单",随机变量的数字特征
矩的定义与求解,"1、$k$阶原点矩：$E\left(X^{k}\right), \quad k=1,2, \cdots $
2、$k$阶中心距：$E\left\{[X-E(X)]^{k}\right\}, \quad k=1,2, \cdots$
3、$k+l$阶混合原点矩：$E\left(X^{k} Y^{l}\right), \quad k, l=1,2, \cdots$
4、$k+l$阶混合中心矩：$E\left\{[X-E(X)]^{k}[Y-E(Y)]^{\iota}\right\}, \quad k, l=1,2, \cdots$","基础, 简单",随机变量的数字特征
独立与不相关,"定义：
1、协方差定义：$\operatorname{Cov}(X, Y)=E\{[X-E(X)][Y-E(Y)]\}$
2、相关系数定义：$\rho_{X Y}=\frac{\operatorname{Cov}(X, Y)}{\sqrt{D(X)} \sqrt{D(Y)}}$
注意：协方差要求$E\{[X-E(X)][Y-E(Y)]\}$存在（不存在是什么情况）
注意：相关系数要求$D(X) D(Y) \neq 0$；如果$D(X) D(Y)=0$, 则$\rho_{X Y}=0$
——————————————————————————
性质：
1、协方差公式1：$C o v ( X , Y ) = E ( X Y ) - E ( X ) E ( Y ) $（公式展开）
2、协方差公式2：$D ( X \pm Y ) = D ( X ) + D ( Y ) \pm 2 Cov ( X , Y )  $（方差展开公式）
3、协方差性质1：$Cov(X, Y)=Cov(Y, X)$
4、协方差性质2：$\operatorname{Cov}(a X, b Y)=a b \operatorname{Cov}(X, Y)$，其中$a,b$为常数（协方差简化计算）
5、协方差性质3：$\operatorname{Cov}\left(X_{1}+X_{2}, Y\right)=\operatorname{Cov}\left(X_{1}, Y\right)+\operatorname{Cov}\left(X_{2}, Y\right)$（协方差简化计算）
——————————————————————————
相关系数性质：
1、相关系数性质1：$\left|\rho_{X Y}\right| \leqslant 1$
2、相关系数性质2：$\mid \rho_{X Y} \mid=1$的充分必要条件是存在常数$a$和$b$，其中$a \neq 0$, 使得$P\{Y=a X+b\}=1$（即相关是两个变量存在线性关系，相反如果完全没有线性关系，那么相关系数就是0）
——————————————————————————
独立与不相关的关系：
1、如果随机变量$X$和$Y$相互独立，则$X$和$Y$必不相关；反之，$X$和$Y$不相关时，$X$和$Y$却不一定相互独立（相关系数$\rho_{X Y}=0$只能说明变量之间是不相关的，不能说是互相独立的（没有线性关系不一定没有其它类型关系））
2、对二维正态随机变量$(X,Y)$,$X$和$Y$相互独立的充分必要条件是$\rho=0$（二维正态随机变量相互独立与不相关是等价的）
——————————————————————————
相关性求解：（协方差和相关系数）（相关系数可以判断变量是否相关）
0、先求解期望和方差（可利用期望和二阶原点矩求解）
1、利用协方差的定义求解协方差
2、运用相关系数的定义求解相关系数
技巧1、对于组合的变量求解协方差时，利用协方差性质分解成相关和不相关的两部分（随机变量和的分解，级数的分解），不相关的一部分为0，可以简化协方差的计算
技巧2、事件的对称性的应用：多个事件除了符号表示，内涵是一样的，有效利用（具有对称性）可以简化求解协方差中的具体参数（中心距之类的）<复习全书P517 例9>
——————————————————————————
判断两个随机变量是否独立：
1、利用变量独立的定义：独立时$P\{X \le a, Y \le a\} = P\{X \le a\}P\{Y \le a\}$，如果需要证明变量不独立利用事件包含的关系证明这个式子不能取等号即可（反证法）
2、二维正态分布如果相关系数为0，则两个变量也是相互独立的
注意：如果事件之间有关联，包含关系，则肯定是相关的，利用关联或者包含的事件不满足变量独立的定义求解，包含关系会导致$P\{X \le a, Y \le a\} = P\{X \le a\}$这种类似的情况（随机变量的区间存在包含关系）","中等, 基础, 疑问",随机变量的数字特征
求解期望,"简单的事件期望（单一）：
1、求解事件的分布律
2、根据定义计算期望
——————————————————————————
复杂的事件期望（事件的组合、重复类型，独立或者不独立，不影响期望的和差计算）：
1、将事件分解为简单的事件（分解的是事件，组合的是期望）
2、简单的事件利用期望的定义求解
3、将简单事件的期望进行组合
——————————————————————————
组合与重复求解期望样例：
1、筛子独立的抛三次，拆分成每一次
2、从N件产品取出n件产品，求解次品个数的期望，拆分成每一件是次品的期望，因为是求解次数，所以需要将取出是次品的变量的值设置为1即可，如果是求取出良品的个数的期望，则设置取出是良品的变量的值为1<复习全书P505 9>
3、独立重复实验n次，拆分成每一次
4、将n个球放入到N个盒子，拆分成对每一个盒子含有球的概率，对于每一个盒子，n个球过来，求解这n个球放入的概率（可以先求对立事件n个球都没有放入的概率），并将盒子有球变量设置为1（对应着这一个盒子有球）这样可以得到一个盒子有球的期望，虽然各个盒子不是独立的，但是期望的性质并没有要求独立性（妙蛙），所以可以求解
注意：对于复杂事件求解期望无论事件是否独立都可以，因为期望的性质并没有限制事件是否独立
——————————————————————————
求解独立同分布的$X,Y$，$Z=min(X,Y)$的数学期望：
1、对于类似的复杂的函数都是用二维函数定义求解：$E(Z)=E[g(X, Y)]=\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) f(x, y) \mathrm{d} x \mathrm{~d} y$
2、可以先对变量进行归一化处理（将两个变量表示的函数转换成一个变量表示的函数？），归一化的函数可以利用期望的定义进行求解
3、非标准正态分布的函数转换成标准正态分布求解（正态分布标准化），可以简化计算
——————————————————————————
从概率密度求解期望：（或与变量函数进行组合）
1、求解原始变量的期望：依据连续型随机变量期望的一维定义计算
2、求解原变量一维函数的期望：依据连续型随机变量期望的一维函数定义计算
3、求解原变量二维函数的期望：依据连续型随机变量期望的二维函数定义计算（注意该情况下可能会以实际的例子出题，概率密度可能需要根据题意进行求解）（如果求解某个与另外两个连续变量相关的变量的期望，则就是这种二维函数期望类型的，即如果出现多变量组合，就组合成函数形式，求函数期望）
4、验证泊松分布的期望时，注意利用泊松分布的级数和为1的性质","中等, 思路, 疑问",随机变量的数字特征
求解随机变量与期望接近程度,"随机变量与期望的接近程度：（粗略估计）
1、切比雪夫不等式：$P\{|X-\mu| \geqslant \varepsilon\} \leqslant \frac{\sigma^{2}}{\varepsilon^{2}}$，正数 $\varepsilon$任意，随机变量$X$具有期望$E(X)=\mu$，方差$D(X)=\sigma^{2}$（该式子表示，越偏离中心范围越大，其概率越小）
注意：切比雪夫不等式主要用于估计概率，证明概率不等式","基础, 简单",大数定律和中心极限定理
随机变量序列依概率收敛的情况-大数定律,"大数定律：
1、依概率收敛的定义：$\lim_{n \rightarrow \infty} P\{|X_n-A| \le \varepsilon \}=1$，对任意$\varepsilon > 0$成立
2、切比雪夫大数定律：$\lim_{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{i=1}^{n} X_{i}-\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}\right)\right|<\varepsilon\right\}=1$，其中$X_{1}, X_{2}, \cdots, X_{n}, \cdots$是一列相互独立 的随机变量(或者两两不相关), 它们的期望与方差分别为$E\left(X_{k}\right)$, $D\left(X_{k}\right)(k=1,2, \cdots)$，并且存在常数$C$, 使得$D\left(X_{k}\right) \leqslant C(k=1,2, \cdots)$
3、辛钦大数定律（独立同分布的序列）：$\lim_{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1$，数学期望 $E\left(X_{k}\right)=\mu,(k=1,2, \cdots)$；任意 $\varepsilon>0$
4、伯努利大数定律（$n$次独立重复试验中事件发生的次数$X_n$）：$\lim_{n \rightarrow \infty} P\left\{\left|\frac{X_n}{n}-p\right|<\varepsilon\right\}=1$或者$\lim_{n \rightarrow \infty} P\left\{\left|\frac{X_n}{n}-p\right| \geqslant \varepsilon\right\}=0$，任意$\varepsilon>0$（这时随机变量就不是序列的形式了，但是可以将二项分布拆开看作0-1分布）
注意：切比雪夫大数定律并未要求同分布；切比雪夫大数定律是切比雪夫不等式的推论
注意：辛钦大数定律将切比雪夫大数定律推向了特殊，对趋向的值做了化简（要求同分布）
注意：伯努利大数定律将辛钦大数定律推向了特殊，对分布做了特殊要求（可以看作是0-1分布序列）
——————————————————————————
求解事件依概率收敛的值：
1、根据事件的类型套用相应的大数定律即可","中等, 基础",大数定律和中心极限定理
依概率收敛的情况-中心极限定理,"中心极限定理：
1、棣莫弗一拉普拉斯定理（二项分布）：$\lim _{n \rightarrow \infty} P\left\{\frac{X_{n}-n p}{\sqrt{n p(1-p)}} \leqslant x\right\}=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} \mathrm{e}^{-\frac{t^{2}}{2}} \mathrm{~d} t=\Phi(x)$（该定理说明二项分布在n充分大时，随机变量经过标准化之后（按照二项分布的期望和方差标准化），接近标准正态分布）
2、列维一林德伯格定理（独立同分布）：$\lim_{n \rightarrow \infty} F_{n}(x)=\lim_{n \rightarrow \infty} P\left\{\frac{\sum_{k=1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma} \leqslant x\right\}=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} \mathrm{e}^{-\frac{t^{2}}{2}} \mathrm{~d} t=\Phi(x)$，随机变量之间互相独立，服从同一分布，具有相同的均值$\mu$和方差$\sigma^2$（均值和方差需要都存在），则随机变量的标准化分布$Y_{n}=\frac{\sum_{k=1}^{n} X_{k}-E\left(\sum_{k=1}^{n} X_{k}\right)}{\sqrt{D\left(\sum_{k=1}^{n} X_{k}\right)}}=\frac{\sum_{k=1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma}$成立上式（该定理说明任何同分布在n充分大时，随机变量经过标准化之后（按照同分布的期望和和方差和来进行标准化），接近标准正态分布）
——————————————————————————
利用中心极限定理求解事件的概率：
1、判断事件的类型：二项分布或者独立同分布（问题：有些事件看似不是二项分布但是可以转换成二项分布？三项，求解一项的概率啥的）；有可能需要利用和的关系转换为相反的事件的概率（反向操作）
2、求解二项分布或独立同分布的均值和方差
3、求解标准化随机变量的范围（原始范围与标准化之后的范围对照）
4、利用分位数和标准化后的分布的性质（正态分布性质等）求解","中等, 基础",大数定律和中心极限定理
大数定律和中心极限定理的理解,"1、大数定律：各种类型的分布在随机变量较多时，收敛的值
2、中心极限定理：描述了当同分布的随机变量较多时，总体上会服从正态分布，正态分布的参数与随机变量的均值和方差有关，并且可以转换成标准正态分布（为了方便利用标准正态分布的分位数进行求解）",思路,大数定律和中心极限定理
总体、样本、统计量定义,"1、总体：研究对象的某项数量指标$X$的全体
2、样本：$X_1,X_2,\cdots X_n$相互独立且同分布，则称该序列是总体$X$的简单随机样本（样本）
3、统计量：由样本构造的不含未知数的函数",基础,数理统计的基本概念
样本的数字特征,"数字特征：
1、样本均值：$\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i}$
2、样本方差：$S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\frac{1}{n-1}\left(\sum_{i=1}^{n} X_{i}^{2}-n \bar{X}^{2}\right)$（样本方差和方差是具有区别的）
3、标准差：$S$
4、样本$k$阶(原点) 矩：$A_{k}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}, k=1,2, \cdots$（原点矩的和形式）
5、样本k阶中心矩：$B_{k}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{k}, k=2,3, \cdots$（原点矩的和形式）（中心是根据样本均值来定的）
——————————————————————————
数字特征性质：
1、样本均值期望：$E(\bar{X}) = \mu$（样本均值公式代入证明）
2、样本均值方差：$D(\bar{X}) = \frac{\sigma^2}{n}$（样本均值公式代入证明）
3、样本方差均值：$E(S^2) = \sigma^2$（样本方差公式代入证明）
4、样本均值期望推广：若总体$X$的$k$阶原点矩$E(X^k)=\mu_k$存在，当$n$趋近于无穷时，样本的$k$阶原点矩$\frac{1}{n}\sum_{i=1}^{n}X_i^k$依概率收敛于$\mu_k$（样本数量较多时，样本均值收敛于总体均值）","基础, 简单",数理统计的基本概念
常用统计抽样分布-卡方、T、F,"卡方分布：
0、定义：$\chi^{2} = X_1^2+X_2^2+\cdots+X_n^2 \sim \chi^{2}(n)$，自由度为$n$，$X_1,X_2,\cdots ,X_n$相互独立且服从标准正态分布
1、上侧$\alpha$分位数定义：$P\left\{\chi^{2}>\chi_{\alpha}^{2}(n)\right\}=\int_{\chi_{\alpha}^{2}(n)}^{+\infty} f(t) \mathrm{d} t=\alpha$
2、卡方均值：$E\left(\chi^{2}\right)=n$
3、卡方方差：$D\left(\chi^{2}\right)=2 n$
4、可加性：$\chi_{1}^{2}+\chi_{2}^{2} \sim \chi^{2}\left(n_{1}+n_{2}\right)$，其中$\chi_{1}^{2}, \chi_{2}^{2}$相互独立，$\chi_{1}^{2} \sim \chi^{2}\left(n_{1}\right)$，$\chi_{2}^{2} \sim \chi^{2}\left(n_{2}\right)$
注意：分位数是将面积（概率）与x轴的坐标对应了起来，卡方分布只有右边
——————————————————————————
T分布：
0、定义：$t=\frac{X}{\sqrt{Y/n}} \sim t(n)$，其中$X \sim N(0,1)$，$Y\sim \chi^{2}\left(n\right)$，且$X,Y$相互独立
1、上侧$\alpha$分位数定义：$P\left\{t>t_{\alpha}(n)\right\}=\int_{t_{\alpha}(n)}^{+\infty} f(t) \mathrm{d} t=\alpha$，
2、分位数性质：$t$分布具有对称性，$t_{1-\alpha}(n)=t_{\alpha}(n)$
注意：分位数是将面积（概率）与x轴的坐标对应了起来，T分布是关于X轴对称的
——————————————————————————
F分布：
0、定义：$F=\frac{U / n_{1}}{V / n_{2}} \sim F\left(n_{1}, n_{2}\right)$，其中$U \sim \chi^{2}\left(n_{1}\right)$，$ V \sim \chi^{2}\left(n_{2}\right)$，且$U,V$相互独立；并且由定义可知$\frac{1}{F} \sim F\left(n_{2}, n_{1}\right)$
1、上侧$\alpha$分位数定义：$P\left\{F>F_{\alpha}\left(n_{1}, n_{2}\right)\right\}=\int_{F_{\alpha}\left(n_{1}, n_{2}\right)}^{+\infty} f(t) \mathrm{d} t=\alpha$
2、分位数性质：$F_{1-\alpha/2}(n_{2},n_{1})=\frac{1}{F_{{\alpha}/{2}}\left(n_{1}, n_{2}\right)}$（三变性质）
注意：分位数是将面积（概率）与x轴的坐标对应了起来，F分布只有右边","基础, 简单",数理统计的基本概念
常用统计抽样分布-正态（区间估计和假设检验的核心）,"单个正态总体：
1、定义：设总体$X \sim N\left(\mu, \sigma^{2}\right), X_{1}, X_{2},\cdots, X_{n}$是来自$X$的样本，样本均值$\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i}$, 样本方差$S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}$
2、性质
2.1 样本均值分布：$\bar{X} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)$，标准化之后为$U=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)$
2.2 样本方差构造卡方分布：$\chi^{2}=\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$（推导：$\frac{(n-1) s^{2}}{\sigma^{2}} =\frac{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}{\sigma^{2}} =\sum_{i=1}^{n}\left(\frac{x_{i}}{\sigma}-\frac{\bar{x}}{\sigma}\right)^{2} =\sum_{i=1}^{n}\left(\frac{x_{i}-\mu}{\sigma}-\frac{\bar{x}-\mu}{\sigma}\right)^{2} =\sum_{i=1}^{n}\left(Z_{i}-\bar{Z}\right)^{2} =\sum_{i=1}^{n} Z_{i}^{2}-n \bar{Z}^{2}$）
2.3 样本均值和样本方差构造$T$分布：$T=\frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1)$（推导：利用标准化的$U$和满足卡方分布的$\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$构造）
2.4 中心矩分布：$\chi^{2}=\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2} \sim \chi^{2}(n)$（注意与样本方差构造卡方分布的区别）（推导：就是将样本标准化成标准正态分布后的平方和）
——————————————————————————
两个正态总体：
1、定义：设$X_{1}, X_{2}, \cdots, X_{n_{1}}$与$Y_{1}, Y_{2}, \cdots,Y_{n_{2}}$分别是来自正态总体$N\left(\mu_{1}, \sigma_{1}^{2}\right)$和$N\left(\mu_{2}, \sigma_{2}^{2}\right)$的样本,且这两个样本相互独立. 设$\bar{X}=\frac{1}{n_{1}} \sum_{i=1}^{n_{1}} X_{i}$，$\bar{Y}=\frac{1}{n_{2}} \sum_{i=1}^{n_{2}} Y_{i}$分别是这两个样本的样本均值; $S_{1}^{2}=\frac{1}{n_{1}-1} \sum_{i=1}^{n_{1}}\left(X_{i}-\bar{X}\right)^{2}$, $S_{2}^{2}=\frac{1}{n_{2}-1} \sum_{i=1}^{n_{2}}\left(Y_{i}-\bar{Y}\right)^{2}$分别是这两个样本的样本方差
2、性质
2.1 均值差构造的正态的分布：$\bar{X}-\bar{Y} \sim N\left(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}\right)$（即正态分布的组合），标准化$ U=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(0,1)$
2.2 均值和样本方差构造$T$分布（需要$\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2}$）：$\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)$，$S_{w}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}, \quad S_{w}=\sqrt{S_{w}^{2}}$（推导：利用上述标准化的$U$和满足卡方分布的$\frac{(n_1-1) S_1^{2}}{\sigma_1^{2}} \sim \chi^{2}(n_1-1)$和$\frac{(n_2-1) S_2^{2}}{\sigma_2^{2}} \sim \chi^{2}(n_2-1)$，以及卡方分布具有可加性，以及$U$和相加后的卡方分布之间的独立性）
2.3 样本方差构造$F$分布：$\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}} \sim F\left(n_{1}-1, n_{2}-1\right)$（推导：满足卡方分布的$\frac{(n_1-1) S_1^{2}}{\sigma_1^{2}} \sim \chi^{2}(n_1-1)$和$\frac{(n_2-1) S_2^{2}}{\sigma_2^{2}} \sim \chi^{2}(n_2-1)$，以及两个卡方分布之间的独立性）
疑问：对于构造T分布时，标准化的U和相加后的卡方分布为什么具有独立性","困难, 基础, 疑问",数理统计的基本概念
总体的样本的相关计算,"样本满足条件的概率：（或已知概率求解未知参数）
1、将来自总体的样本依照常用的统计抽样分布的条件转换，得到标准分布（概率论思想：标准化）
2、依照标准分布求解概率
——————————————————————————
样本满足某种分布：（证明）
1、依照常用的统计抽样分布的性质（各部分的独立性）对样本函数的各个部分进行证明验证
——————————————————————————
样本构成的函数的期望：（类似于矩估计量的进一步求解）
1、单个正态总体的统计抽样分布性质
2、函数的拆分组合，依据概率分布的定义求解：$P\{ X_n > max(X_1,X_2,\cdots,X_{n-1})\} = P\{ X_n > X_1,X_n >X_2,\cdots,X_n >X_{n-1})\}$
——————————————————————————
样本的联合概率密度或概率分布：
1、相互独立的随机变量的联合概率密度：连续情况下，若已知样本概率密度，则来自总体的样本的联合概率密度为各个样本的概率密度相乘
2、先求得分布函数：在题目已知条件下，可以求得联合概率密度的分布函数，由分布函数求导得到概率密度
3、相互独立的随机变量的联合概率分布：离散情况下，来自总体的样本的联合概率分布为各个样本的概率分布乘积
4、离散变量均值的分布：离散情况下，求解均值（一种样本函数）的分布（如果总体分布为泊松分布，注意泊松分布具有可加性）",中等,数理统计的基本概念
估计定义,"1、点估计：用样本$X_1,X_2,\ldots,X_n$构造统计量$\hat \theta(X_1,X_2,\ldots,X_n)$来估计未知参数$\theta$称为点估计，统计量$\hat \theta(X_1,X_2,\ldots,X_n)$称为估计量
2、无偏估计量：$\hat \theta$是$\theta$的无偏估计量，如果$E(\hat \theta)=\theta$，则称$\hat \theta=\hat \theta(X_1,X_2,\ldots,X_n)$是未知参数$\theta$的无偏估计量
3、更有效估计量：设$\hat \theta_1$和$\hat \theta_2$都是$\theta$的无偏估计量，且$D(\hat \theta_1) \le D(\hat \theta_2)$，则称$\hat \theta_1$比$\hat \theta_2$更有效，或$\hat \theta_1$比$\hat \theta_2$更有效估计量
4、一致估计量：设$\hat \theta(X_1,X_2,\ldots,X_n)$是$\theta$的估计值，如果估计值$\hat \theta$依概率收敛于未知参数$\theta$，则称$\hat \theta(X_1,X_2,\ldots,X_n)$是$\theta$的一致估计量",基础,参数估计
求估计量-矩估计,"矩估计法：
1、未知参数表示：列出未知参数用矩表示的表示式（列出未知参数与总体的矩的关系式）（当一阶矩与未知参数没有关系时（比如一阶矩为0），求解二阶矩）（备注：其中矩可以根据题目情况选择原点矩或者中心矩，看未知参数用总体的什么矩表示更方便）
2、样本矩替换矩得到估计量：由样本的等于总体矩得到未知参数的估计量（将关系式中的总体矩替换成样本矩，未知参数就需要转换为估计量的说法，变成了估计量与样本矩的表示式，样本矩是可以从样本计算的，所以估计量就可以求出来了）
3、进一步求解估计量的数字特征：当需要求解估计量或者估计量表达式的期望时，将求解的估计量（用样本表示的）代入到待求解的期望表达式，转换成求解样本的数字特征，由于样本具有与总体一样的数字特征，所以使用总体的概率密度或者相关表达式进行求解（求解的结果等于未知参数或者未知参数的表达式（与估计量一样的表达式））
备注：矩估计含义是以已知的样本的矩来估计总体的矩中的未知参数
注意：在矩估计中是用不到样本方差的表达式的（因为都是用矩估计的）
——————————————————————————
求解参数的矩估计量：
1、一个待估计参数只需要一个方程，一阶矩（如果一阶矩与未知参数没有关系，需要求二阶矩）
2、两个待估计参数需要两个方程，一阶矩和二阶矩方程
3、列出的方程的关系是样本的矩和总体的矩相等或者是样本中心矩和总体中心矩相等
注意：参数的估计量中的未知变量只能有样本相关的量（如果样本是具体的数值，则估计量也是数值）","中等, 基础",参数估计
求估计量-最大似然估计法,"1、列出关于未知变量的似然函数（似然函数是根据样本点的值对应的概率密度相乘得到的）
2、有驻点：求解方程达到最大值的点（直接求导或者取对数后求导等于0的点），对应的未知变量的值就是待求解的值
3、没有驻点：从题目中找到关于未知参数的限制关系，根据最大似然函数单调性找到使得最大似然函数最大点的值
注意：写出似然函数后就是求解最大值的问题，如果似然函数存在驻点则在驻点中找；如果由导数没有驻点或不可导，用其它方法找使得似然函数最大值的点","中等, 基础",参数估计
求估计量-区间估计,"区间估计：
1、理解置信区间：当估计未知量时，利用已有的东西（均值，方差，均值差之类的）构成一个分布（正态分布，卡方分布，T分布，F分布）并将分布标准化（标准化后的正态分布，卡方分布，T分布，F分布），置信区间是该标准分布的一个区间内时（该区间的概率值为$1-\alpha$，并叫置信度为$1-\alpha$的置信区间），待估计的未知量的范围（基本公式为$P\{ \theta_1 < \theta < \theta_2 \} = 1-\alpha$，则置信区间为$(\theta_1 , \theta_2)$，也就是标准分布在置信区间内的概率等于置信度）（两侧或者单侧的概率就是$\alpha$）
——————————————————————————
有关置信区间的未知量求解：
1、利用置信区间的性质（正态分布和$T$分布的对称性，$F$分布的三变性质）
注意：对称轴的位置可能不在原点，可绘制坐标图辅助理解","中等, 基础",参数估计
区间估计-一个正态总体的区间估计,"1、一个正态总体的区间估计利用了单个正态总体的抽样分布
2、如果要估计$\mu$，$\sigma^{2}$已知，需要用样本均值构造的正态分布（$\bar{X} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)$，标准化$U=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)$，因为这个分布中除了$\mu$其它值（$\sigma^{2}$，样本个数$n$，样本均值$\bar{X}$）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准正态分布观测的区间，自然会找到$(−u_{\alpha/2},u_{\alpha/2})$，则待估计量$\mu$的估计区间为$\left(\bar{X}-u_{{\alpha}/{2}} \frac{\sigma}{\sqrt{n}}, \quad \bar{X}+u_{{\alpha}/{2}} \frac{\sigma}{\sqrt{n}}\right) $（因为正态分布是双侧的，所以对两侧的概率每一边都是$\alpha/2$，即让标准化的$U$落在$(-u_{{\alpha}/{2}},u_{{\alpha}/{2}})$区间，从而求得$\mu$的估计区间）
3、如果要估计$\mu$，$\sigma^{2}$未知，需要用样本均值和样本方差构造的$T$分布（$T=\frac{\bar{X}-\mu}{S / \sqrt{n}} \sim t(n-1)$，因为这个分布中除了$\mu$其它值（样本方差$S^2$，样本个数$n$，样本均值$\bar{X}$）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准$T$分布观测的区间，自然会找到$(−t_{\alpha/2}(n-1),t_{\alpha/2}(n-1))$，则待估计量$\mu$的估计区间为$\left(\bar{X}-t_{{\alpha}/{2}}(n-1) \frac{S}{\sqrt{n}}, \quad \bar{X}+t_{{\alpha}/{2}}(n-1) \frac{S}{\sqrt{n}}\right)$（因为T分布是双侧的，所以对两侧的概率每一边都是$\alpha/2$，即让标准化的$T$落在$(−t_{\alpha/2}(n-1),t_{\alpha/2}(n-1))$区间，从而求得$\mu$的估计区间）
4、如果要估计$\sigma^{2}$值，需要用样本方差构造的卡方分布（$\chi^{2}=\frac{(n-1) S^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)$，因为这个分布中除了$\sigma^{2}$其它值（样本方差$S^2$，样本个数$n$）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准卡方分布观测的区间，自然会找到$(\chi_{{\alpha}/{2}}^{2}(n-1),\chi_{1-{\alpha}/{2}}^{2}(n-1))$，则待估计量$\sigma^{2}$的估计区间为$\left(\frac{(n-1) S^{2}}{\chi_{{\alpha}/{2}}^{2}(n-1)}, \frac{(n-1) S^{2}}{\chi_{1-{\alpha}/{2}}^{2}(n-1)}\right)$（因为卡方分布是单侧的，所以使单侧的两边的概率每一边都是$\alpha/2$，即让标准化的卡方变量落在$(\chi_{{\alpha}/{2}}^{2}(n-1),\chi_{1-{\alpha}/{2}}^{2}(n-1))$区间，从而求得$\mu$的估计区间）",困难,参数估计
区间估计-两个正态总体的区间估计,"1、两个正态总体的区间估计利用了两个正态总体的抽样分布
2、如果要估计$\mu_1-\mu_2$，$\sigma_{1}^{2}$和$\sigma_{2}^{2}$已知，需要用均值差构造的正态的分布（$\bar{X}-\bar{Y} \sim N\left(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}\right)$，标准化$ U=\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(0,1)$，因为这个分布中除了$\mu_{1}-\mu_{2}$其它值（$\sigma_{1}^{2},\sigma_{2}^{2}$，样本个数$n_1,n_2$，样本均值$\bar{X},\bar{Y}$）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准正态分布观测的区间，自然会找到$(−u_{\alpha/2},u_{\alpha/2})$，则待估计量$\mu_1-\mu_2$的估计区间为$ \left(\bar{X}-\bar{Y}-u_{{\alpha}/{2}} \sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}, \bar{X}-\bar{Y}+u_{{\alpha}/{2}} \sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}\right)$
3、如果要估计$\mu_1-\mu_2$，$\sigma_{1}^{2}$和$\sigma_{2}^{2}$值未知，但是已知$\sigma_{1}^{2}=\sigma_{2}^{2}$，需要用均值和样本方差构造$T$分布（（需要$\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2}$）：$\frac{(\bar{X}-\bar{Y})-\left(\mu_{1}-\mu_{2}\right)}{S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}} \sim t\left(n_{1}+n_{2}-2\right)$，$S_{w}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}, \quad S_{w}=\sqrt{S_{w}^{2}}$，因为这个分布中除了$\mu_{1}-\mu_{2}$其它值（$S_{1}^{2},S_{2}^{2}$，样本个数$n_1,n_2$，样本均值$\bar{X},\bar{Y}$，$\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2}$是T分布的要求）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准$T$分布观测的区间，自然会找到$(−t_{\alpha/2}(n_{1}+n_{2}-2),t_{\alpha/2}(n_{1}+n_{2}-2))$，则待估计量$\mu_1-\mu_2$的估计区间为$\left(\bar{X}-\bar{Y}-t_{{\alpha}/{2}}\left(n_{1}+n_{2}-2\right) S_{w} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right. ,\left.\bar{X}-\bar{Y}+t_{{\alpha}/{2}}\left(n_{1}+n_{2}-2\right) S_{\omega} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}\right)$
4、如果要估计$\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}$值，需要用样本方差构造$F$分布（$\frac{S_{1}^{2} / S_{2}^{2}}{\sigma_{1}^{2} / \sigma_{2}^{2}} \sim F\left(m-1, n-1\right)$，因为这个分布中除了$\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}$其它值（$S_{1}^{2},S_{2}^{2}$，样本个数$n_1,n_2$）都是已知的，可以套用基本公式得出待估计量的置信区间），找一个以$1−α$概率涵盖标准卡方分布观测的区间，自然会找到$(F_{1-\alpha/2}(m−1,n−1)=\frac{1}{F_{{\alpha}/{2}}\left(n−1, m−1\right)},F_{\alpha/2}(m−1,n−1))$，则待估计量$\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}$的估计区间为$\left(\frac{S_{1}^{2}}{S_{2}^{2}} \cdot \frac{1}{F_{{\alpha}/{2}}\left(n_{1}-1, n_{2}-1\right)}, \frac{S_{1}^{2}}{S_{2}^{2}} F_{{\alpha}/{2}}\left(n_{2}-1, n_{1}-1\right.\right)$（因为F分布是单侧的，所以使单侧的两边的概率每一边都是$\alpha/2$，即让标准化的$F$变量落在$(F_{1-\alpha/2}(m−1,n−1)=\frac{1}{F_{{\alpha}/{2}}\left(n−1, m−1\right)},F_{\alpha/2}(m−1,n−1))$区间，从而求得$\mu$的估计区间）",困难,参数估计
无偏估计,"证明随机变量函数是某个值的无偏估计：（或者已知是无偏估计求解未知参数）
方案一：直接求解
1、随机变量函数（平方形式，指数形式）的拆分组合
2、利用特定分布的性质
方案二：求核心部分的分布（随机变量整体是正态分布的）（一定要注意核心分布的求解需要其中的各个变量互相独立，无法验证是否独立时用别的方法）
1、依据：方差的性质$D(a X+b)=a^{2} D(X) $；期望的性质$E(a_1X_1+a_2X_2+\cdots+a_nX_n+b_1+b_2+\cdots+b_m)=a_1E(X_1)+a_2E(X_2)+\cdots+a_nE(X_n)+b_1+b_2+\cdots+b_m$；正态分布变量组合性质（当$X$与$Y$均服从一维正态，且相互独立，就是指$(X, Y)$服从二维正态，$a X+b Y$服从一维正态，其中$\left(a^{2}+b^{2} \neq 0\right)$，这是从多维分布里面拖过来的）
2、步骤：求解核心部分的分布函数（分别求解核心部分的期望和方差，从而得到正态分布）；利用新的正态分布求解即可
注意：样本与总体是同分布的",中等,参数估计
假设检验,"一般步骤：
1、根据实际问题的要求，提出原假设$H_0$及备择假设$H_1$
2、给定显著性水平$\alpha$及样本容量$n$
3、确定检验统计量以及拒绝域的形式
4、按犯第一类错误的概率等于$\alpha$求出拒绝域$W$
5、取样，根据样本计算检验统计量的观测值$t$，当$t$处于拒绝域$W$内拒绝$H_0$，否则接受原假设
注意：常用的统计量构造（单样本、双样本）
注意：如果假设是等号，则拒绝域是双边的；如果假设是小于号，则拒绝域在右边；如果假设是大于号，则拒绝域在左边
——————————————————————————
统计量构造类型：（注意与区间估计的区别是区间估计是双边的，统计量检验只有原假设为等号时是双边的，其它都是单边的）（$\mu_0$和$\sigma_0$都是检验中的临界值）（所有的统计量可以认为是在观测值按照已有的条件标准化）
1、（单样本）检验$\mu$，$\sigma^{2}$已知：$N(0,1) \sim U=\frac{\bar{X}-\mu_{0}}{\sigma / \sqrt{n}}$
2、（单样本）检验$\mu$，$\sigma^{2}$未知： $t(n-1) \sim T=\frac{\bar{X}-\mu_{0}}{S / \sqrt{n}}$
3、（单样本）检验$\sigma^{2}$，$\mu$已知：$X^2(n) \sim \chi^{2}=\frac{1}{\sigma_{0}^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}$
4、（单样本）检验$\sigma^{2}$，$\mu$未知：$X^2(n-1) \sim \chi^{2}=\frac{(n-1) S^{2}}{\sigma^{2}}$
5、（双样本）检验$\mu_1-\mu_2$，$\sigma_{1}^{2}$和$\sigma_{2}^{2}$已知：$N(0,1) \sim U=\frac{\bar{X}-\bar{Y}-\mu_{0}}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}$
6、（双样本）检验$\mu_1-\mu_2$，$\sigma_{1}^{2}$和$\sigma_{2}^{2}$未知但相等：$t(n_1+n_2-2) \sim T=\frac{\bar{X}-\bar{Y}-\mu_{0}}{S_{\omega} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}$
7、（双样本）检验$\sigma_{1}^{2} = \sigma_{2}^{2}$，$\mu_1,\mu_2$已知：$F(n_1,n_2) \sim F=\frac{n_{2} \sum_{i=1}^{n_{1}}\left(X_{i}-\mu_{1}\right)^{2}}{n_{1} \sum_{j=1}^{n_{2}}\left(Y_{j}-\mu_{2}\right)^{2}}$
8、（双样本）检验$\sigma_{1}^{2} = \sigma_{2}^{2}$，$\mu_1,\mu_2$未知：$F(n_1-1,n_2-1) \sim F=\frac{S_{1}^{2}}{S_{2}^{2}}$","中等, 基础",假设检验
假设检验的两类错误,"1、第一类错误（弃真）$\alpha$：可认为原假设$H_0$是正确的，但是样本却在拒绝域里导致拒绝了本是正确的假设（弃真，是指放弃真的原假设），$P\{ 原假设拒绝域| H_0 \}$，解释为原假设正确条件下样本在拒绝域的概率，导致拒绝了真的原假设
2、第二类错误（纳伪）$\beta$：可认为备选假设$H_1$是正确的，但是样本却在原假设的非拒绝域内导致无法拒绝（错误的）原假设从而发生的错误（纳伪，是指接受错误的原假设），$P\{ 原假设拒绝域的对立情况| H_1 \}$，解释为备选假设正确的条件下，样本却在原假设的非拒绝域的概率，导致无法拒绝错误的原假设","中等, 思路",假设检验
统计量的构造,"1、统计量的构造需要考虑需要检验的参数，并且考虑是单样本还是双样本（两个样本之间的比较）
2、考虑一个或者两个正态总体的分布，其中有哪些参数是已知和未知的，确定检验范围（一个正态总体待检验的参数是否等于，小于，大于某个值；两个正态总体的检验参数差值大于，小于等情况），去确定未知参数的情况，从而构造合适的统计量",中等,假设检验